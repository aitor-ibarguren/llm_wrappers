============================= test session starts ==============================
platform linux -- Python 3.10.18, pytest-8.4.2, pluggy-1.6.0
rootdir: /home/runner/work/llm_wrappers/llm_wrappers
plugins: anyio-4.10.0, langsmith-0.4.23, cov-6.2.1
collected 27 items

tests/test_bart_wrapper.py ......                                        [ 22%]
tests/test_faiss_wrapper.py .........                                    [ 55%]
tests/test_flan_t5_wrapper.py ......                                     [ 77%]
tests/test_gpt2_wrapper.py ......                                        [100%]

=============================== warnings summary ===============================
../../../../../opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/faiss/loader.py:28
  /opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/faiss/loader.py:28: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(numpy.__version__) >= "1.19":

../../../../../opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/setuptools/_distutils/version.py:346
  /opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    other = LooseVersion(other)

<frozen importlib._bootstrap>:241
<frozen importlib._bootstrap>:241
  <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute

<frozen importlib._bootstrap>:241
<frozen importlib._bootstrap>:241
  <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute

<frozen importlib._bootstrap>:241
  <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute

tests/test_bart_wrapper.py::TestBARTWrapper::test_peft_train_model
tests/test_bart_wrapper.py::TestBARTWrapper::test_train_model
tests/test_flan_t5_wrapper.py::TestFlanT5Wrapper::test_peft_train_model
tests/test_flan_t5_wrapper.py::TestFlanT5Wrapper::test_train_model
tests/test_gpt2_wrapper.py::TestFlanT5Wrapper::test_peft_train_model
tests/test_gpt2_wrapper.py::TestFlanT5Wrapper::test_train_model
  /opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.
    warnings.warn(warn_msg)

tests/test_bart_wrapper.py::TestBARTWrapper::test_save_and_load_model
tests/test_bart_wrapper.py::TestBARTWrapper::test_train_model
  /opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/transformers/modeling_utils.py:4034: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.
    warnings.warn(

tests/test_bart_wrapper.py::TestBARTWrapper::test_train_model
  /home/runner/work/llm_wrappers/llm_wrappers/bart_wrapper/bart_wrapper.py:305: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
    trainer = Seq2SeqTrainer(

tests/test_flan_t5_wrapper.py::TestFlanT5Wrapper::test_train_model
  /home/runner/work/llm_wrappers/llm_wrappers/flan_t5_wrapper/flan_t5_wrapper.py:310: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
    trainer = Seq2SeqTrainer(

tests/test_gpt2_wrapper.py::TestFlanT5Wrapper::test_peft_train_model
  /opt/hostedtoolcache/Python/3.10.18/x64/lib/python3.10/site-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.
    warnings.warn(

tests/test_gpt2_wrapper.py::TestFlanT5Wrapper::test_train_model
  /home/runner/work/llm_wrappers/llm_wrappers/gpt2_wrapper/gpt2_wrapper.py:316: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
    trainer = Trainer(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
_______________ coverage: platform linux, python 3.10.18-final-0 _______________

Name                                 Stmts   Miss  Cover   Missing
------------------------------------------------------------------
bart_wrapper/__init__.py                 0      0   100%
bart_wrapper/bart_wrapper.py           153     12    92%   35-37, 58, 88-90, 94, 126-128, 135
faiss_wrapper/__init__.py                0      0   100%
faiss_wrapper/faiss_wrapper.py         293     32    89%   77, 118-122, 129-130, 135-137, 141-144, 205-214, 340, 366-373, 392-393, 467-468, 472, 553-555, 557-559
flan_t5_wrapper/__init__.py              0      0   100%
flan_t5_wrapper/flan_t5_wrapper.py     156     12    92%   41-43, 64, 94-96, 100, 132-134, 141
gpt2_wrapper/__init__.py                 0      0   100%
gpt2_wrapper/gpt2_wrapper.py           157     12    92%   38-40, 63, 93-95, 99, 131-133, 140
setup.py                                 2      2     0%   1-3
tests/__init__.py                        0      0   100%
tests/test_bart_wrapper.py              69      2    97%   6, 131
tests/test_faiss_wrapper.py            106      2    98%   6, 208
tests/test_flan_t5_wrapper.py           69      2    97%   6, 131
tests/test_gpt2_wrapper.py              69      2    97%   6, 134
------------------------------------------------------------------
TOTAL                                 1074     78    93%
================= 27 passed, 19 warnings in 193.19s (0:03:13) ==================
