============================= test session starts ==============================
platform linux -- Python 3.10.19, pytest-9.0.1, pluggy-1.6.0
rootdir: /home/runner/work/llm_wrappers/llm_wrappers
plugins: anyio-4.11.0, cov-7.0.0, langsmith-0.4.42
collected 29 items

tests/test_bart_wrapper.py ......                                        [ 20%]
tests/test_faiss_wrapper.py ...........                                  [ 58%]
tests/test_flan_t5_wrapper.py ......                                     [ 79%]
tests/test_gpt2_wrapper.py ......                                        [100%]

=============================== warnings summary ===============================
<frozen importlib._bootstrap>:241
  <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute

<frozen importlib._bootstrap>:241
  <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute

<frozen importlib._bootstrap>:241
  <frozen importlib._bootstrap>:241: DeprecationWarning: builtin type swigvarlink has no __module__ attribute

tests/test_bart_wrapper.py::TestBARTWrapper::test_peft_train_model
tests/test_bart_wrapper.py::TestBARTWrapper::test_train_model
tests/test_flan_t5_wrapper.py::TestFlanT5Wrapper::test_peft_train_model
tests/test_flan_t5_wrapper.py::TestFlanT5Wrapper::test_train_model
tests/test_gpt2_wrapper.py::TestFlanT5Wrapper::test_peft_train_model
tests/test_gpt2_wrapper.py::TestFlanT5Wrapper::test_train_model
  /opt/hostedtoolcache/Python/3.10.19/x64/lib/python3.10/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.
    warnings.warn(warn_msg)

tests/test_bart_wrapper.py::TestBARTWrapper::test_save_and_load_model
tests/test_bart_wrapper.py::TestBARTWrapper::test_train_model
  /opt/hostedtoolcache/Python/3.10.19/x64/lib/python3.10/site-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.
    warnings.warn(

tests/test_bart_wrapper.py::TestBARTWrapper::test_train_model
  /home/runner/work/llm_wrappers/llm_wrappers/bart_wrapper/bart_wrapper.py:305: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
    trainer = Seq2SeqTrainer(

tests/test_flan_t5_wrapper.py::TestFlanT5Wrapper::test_train_model
  /home/runner/work/llm_wrappers/llm_wrappers/flan_t5_wrapper/flan_t5_wrapper.py:310: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
    trainer = Seq2SeqTrainer(

tests/test_gpt2_wrapper.py::TestFlanT5Wrapper::test_peft_train_model
  /opt/hostedtoolcache/Python/3.10.19/x64/lib/python3.10/site-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.
    warnings.warn(

tests/test_gpt2_wrapper.py::TestFlanT5Wrapper::test_train_model
  /home/runner/work/llm_wrappers/llm_wrappers/gpt2_wrapper/gpt2_wrapper.py:316: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
    trainer = Trainer(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
_______________ coverage: platform linux, python 3.10.19-final-0 _______________

Name                                 Stmts   Miss  Cover   Missing
------------------------------------------------------------------
bart_wrapper/__init__.py                 0      0   100%
bart_wrapper/bart_wrapper.py           153     12    92%   35-37, 58, 88-90, 94, 126-128, 135
faiss_wrapper/__init__.py                0      0   100%
faiss_wrapper/faiss_wrapper.py         387     44    89%   87, 132-136, 149-151, 155-158, 163-165, 255-264, 398-402, 421, 426-433, 452-453, 527-528, 532, 604-605, 610, 651-652, 659-660, 739-741, 743-745
flan_t5_wrapper/__init__.py              0      0   100%
flan_t5_wrapper/flan_t5_wrapper.py     156     12    92%   41-43, 64, 94-96, 100, 132-134, 141
gpt2_wrapper/__init__.py                 0      0   100%
gpt2_wrapper/gpt2_wrapper.py           157     12    92%   38-40, 63, 93-95, 99, 131-133, 140
setup.py                                 2      2     0%   1-3
tests/__init__.py                        0      0   100%
tests/test_bart_wrapper.py              69      2    97%   6, 131
tests/test_faiss_wrapper.py            120      2    98%   6, 244
tests/test_flan_t5_wrapper.py           69      2    97%   6, 131
tests/test_gpt2_wrapper.py              69      2    97%   6, 134
------------------------------------------------------------------
TOTAL                                 1182     90    92%
================= 29 passed, 15 warnings in 201.10s (0:03:21) ==================
